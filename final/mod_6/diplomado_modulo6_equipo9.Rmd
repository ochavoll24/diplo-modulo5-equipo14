---
title: "Tarea 1: Reducción de dimensión usando PCA, t-SNE y UMAP"
author: "Equipo 9 - Aprendizaje no supervisado"
date: "2025-08-22"
output:
  html_document:
    theme: flatly
    toc: yes
---

<style type="text/css">
.main-container {
  max-width: 1200px;
  margin-left: auto;
  margin-right: auto;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Libraries 

library(dplyr)
library(readr)
library(ggplot2)
library(skimr)
library(lubridate)
library(stringr)
library(tidyr)
#library(tidyverse) #
library(purrr)
library(stringi)

### PCA libraries

#library(tidymodels)
library(broom)
library(tidytext)
library(recipes)


library(knitr)
library(kableExtra)
library(GGally)
library(psych)

library(Hmisc)
#library(autoplot)

#library(rgl)
library(plotly)
library(ggforce)
library(FactoMineR)  
library(factoextra)
library(ggcorrplot) #correlation plots
library(rstatix) #prueba de bartlet?
library(ggfortify) # extends autoplot to admin stats output variables
library(forcats) #  changes the order ## used in code order of levels by the order in which they appear
#library(ggord)

library(tidymodels)
library(embed)        
library(tune)
library(dials)
library(FNN)
library(cluster)
library(uwot)


library(patchwork)    
library(corrplot)     
library(data.table)
library(scattermore)
library(corrr)

theme_set(theme_bw(16))


options(scipen = 999)

# Functions

## Here for the functions


```

# Introducción.

Esta es una breve introducción a reducción de dimensión

### Análisis exploratorio de Datos


# Objetivo

El objetivo principal de este proyecto es la reducción de dimensión de los datos mediante la implementación de tres modelos: Análisis de Componentes Principales (PCA), t-distributed Stochastic Neighbor Embedding (t-SNE) y Uniform Manifold Approximation and Projection (UMAP).

En el caso de PCA, se busca que dos o tres componentes principales capturen entre el 60% y el 80% de la varianza, considerando que el número de variables originales es relativamente bajo.

Para los modelos t-SNE y UMAP, el propósito es obtener representaciones en nuevas dimensiones con baja correlación entre sí, evaluando además su capacidad de separar de manera coherente la variable respuesta “aprobar o rechazar el crédito”, lo que permitirá analizar si las proyecciones resultantes facilitan una clara diferenciación binaria en el espacio reducido.


# Ejección de Modelos

Este es un breve texto para hablar de esta sección 


###  Modelo PCA

Copiar aquí el código del modelo


###  Modelo t-SNE

Copiar aquí el código del modelo


###  Modelo UMAP

Copiar aquí el código del modelo

### Modelo UMAP con 3 dimensiones

A partir de los resultados obtenidos con el modelo bidimensional, se procedió a implementar una variante de tres dimensiones con el fin de evaluar si, en cortes adicionales entre los componentes, UMAP lograba una mejor diferenciación de la variable respuesta. Para este ejercicio, se excluyó la variable income_annum, dado que mostraba una correlación predominante con la aprobación del crédito.

#### Tuning de hiperparámetros

Para el ajuste de hiperparámetros se utilizó una búsqueda en malla, en la cual se incrementaron los valores de n_neighbors y, de manera paralela, los de min_dist, en comparación con los parámetros estándar definidos por UMAP. La distancia utilizada fue "euclidean".

n_neighbors = c(20, 30)
min_dist = c(0.05,  0.1)

```{r include=FALSE}

loan_scaled <- 
  readr::read_csv("loan_approval_dataset.csv") %>% 
  select(-education,-self_employed, -income_annum) %>%
  mutate( across(where(is.numeric), scale) ) 
  


df <-loan_scaled

umap_params = expand.grid(n_neighbors = c(20, 30) , min_dist = c(0.05,  0.1)   ) #c(0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.75, 1.1)

#umap_params = expand.grid(n_neighbors = c(3, 5, 8, 12, 20, 30) , min_dist = c(0.001, 0.005, 0.01, 0.05, 0.1)   ) #c(0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 

#umap_params = expand.grid(n_neighbors = c(10),min_dist = c(0.5))

umaps = lapply(seq(nrow(umap_params)), function(i) {
    emb = umap(
      X = df[,-1],
      n_components = 3,
      metric = "euclidean",  #manhattan hamming
      n_neighbors = umap_params$n_neighbors[i],
      min_dist  = umap_params$min_dist[i]
      )

  return(emb)
})

d = rbindlist(lapply(seq(nrow(umap_params)), function(i) {
  data.table(
    x = umaps[[i]][,1],
    y = umaps[[i]][,2],
    z = umaps[[i]][,3],
    n_neighbors = umap_params$n_neighbors[i],
    min_dist = umap_params$min_dist[i],
    group =  df$loan_status
  )
}))

plot_db<-
  d %>% 
    group_by(n_neighbors,min_dist) %>% 
    mutate( slice_num =  cur_group_id()) %>% 
    ungroup

cat("Transformacion UMAP con valiación cruzada en 3 dimensiones completada!\n")
```

Se generaron las proyecciones de los componentes UMAP1 vs. UMAP2 para cada combinación de parámetros evaluada. Los resultados obtenidos muestran patrones visuales muy similares a los observados en el modelo base, sin evidenciar mejoras significativas en la separación de la variable respuesta.


```{r echo=FALSE, fig.height=8, fig.width=8}

plot_db %>%
  dplyr::filter(slice_num %in% c( 1:4 ) ) %>% 
ggplot() +
  geom_scattermore(
    mapping = aes(x = x, y = y,colour=group),
    pointsize = 2
  ) +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.title = element_blank(),
    legend.position = "none"
  ) +
  facet_wrap(
             min_dist ~ n_neighbors 
             ,labeller = label_both
             ,scales = "free"
             ) +
  theme_bw() +
  labs(title = "Loan Approval dataset: UMAP1 vs. UMAP2")
```

Se analizaron las proyecciones de los componentes UMAP1 vs. UMAP3 para cada combinación de parámetros. En este caso, se observó una mayor separación en la variable respuesta al utilizar distancias más amplias (min_dist = 0.1) junto con vecindarios ligeramente mayores (n_neighbors = 20–30).


```{r echo=FALSE, fig.height=8, fig.width=8}

plot_db %>%
  dplyr::filter(slice_num %in% c( 1:4 ) ) %>% 
ggplot() +
  geom_scattermore(
    mapping = aes(x = x, y = z,colour=group),
    pointsize = 2
  ) +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.title = element_blank(),
    legend.position = "none"
  ) +
  facet_wrap(
             min_dist ~ n_neighbors 
             ,labeller = label_both
             ,scales = "free"
             ) +
  theme_bw() +
  labs(title = "Loan Approval dataset: UMAP1 vs. UMAP3")
```


Se analizaron las proyecciones de los componentes UMAP2 vs. UMAP3 para cada combinación de parámetros. En este caso, se observó una mayor separación en la variable respuesta al utilizar distancias más amplias (min_dist = 0.1) junto con vecindarios ligeramente mayores (n_neighbors = 20–30).

```{r echo=FALSE, fig.height=8, fig.width=8}

plot_db %>%
  dplyr::filter(slice_num %in% c( 1:4 ) ) %>% 
ggplot() +
  geom_scattermore(
    mapping = aes(x = y, y = z,colour=group),
    pointsize = 2
  ) +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.title = element_blank(),
    legend.position = "none"
  ) +
  facet_wrap(
             min_dist ~ n_neighbors 
             ,labeller = label_both
             ,scales = "free"
             ) +
  theme_bw() +
  labs(title = "Loan Approval dataset: UMAP2 vs. UMAP3")
```

Al incrementar la dimensionalidad a tres componentes, se observó una mejor separación de la variable respuesta. Este resultado sugiere que la estructura de los datos presenta una mayor complejidad, la cual no puede ser representada de manera adecuada en un espacio bidimensional.

Finalmente, con el propósito de comprender con mayor profundidad la estructura revelada por UMAP, se calcularon las diez principales correlaciones entre las variables originales y los tres componentes obtenidos, considerando el caso con min_dist = 0.1 y n_neighbors = 30. Como se aprecia en la tabla, algunos features presentan correlaciones destacadas con los componentes 2 y 3, lo que aporta evidencia adicional sobre la complejidad de la estructura latente en los datos.


```{r echo=FALSE, warning=FALSE}

final_recipe <-
  recipe(~ ., data = loan_scaled) %>%
  step_nzv(all_predictors()) %>%
  #step_normalize(all_numeric_predictors()) %>%
  #step_corr(all_numeric_predictors(), threshold = 0.85) %>%
  step_umap(all_predictors(), 
            num_comp = 3,
            neighbors = 30,
            min_dist = 0.1,
            learn_rate = 1,
            metric = "euclidean" ,  # metric = c("euclidean", "manhattan", "cosine", "hamming")
            epochs = 400,
            seed = c(24,123)
            )

set.seed(24)

#seed 19, slice 2 or100

# Prep the recipe (fit the preprocessing steps including UMAP)
final_prep <- prep(final_recipe, training = loan_scaled)

# Transform the data using the prepped recipe
umap_results <- bake(final_prep, new_data = loan_scaled)

analyze_umap_correlations <- function(original_data, umap_results, n_top = 10) {
  
  # Combine original features with UMAP components
  combined_data <- bind_cols(
    original_data %>% select(where(is.numeric)),
    umap_results %>% select(starts_with("UMAP"))
  )
  
  # Get feature names and UMAP component names
  feature_names <- original_data %>% select(where(is.numeric)) %>% names()
  umap_names <- umap_results %>% select(starts_with("UMAP")) %>% names()
  
  # Calculate correlations manually
  correlations <- tibble()
  
  for (umap_comp in umap_names) {
    for (feature in feature_names) {
      cor_val <- cor(combined_data[[feature]], combined_data[[umap_comp]], use = "complete.obs")
      
      correlations <- bind_rows(
        correlations,
        tibble(
          term = feature,
          component = umap_comp,
          correlation = cor_val
        )
      )
    }
  }
  correlations <- correlations %>%
    filter(!is.na(correlation)) %>%
    group_by(component) %>%
    mutate(abs_correlation = abs(correlation)) %>%
    slice_max(abs_correlation, n = n_top) %>%
    arrange(component, desc(abs_correlation))
  
  return(correlations)
}

analyze_umap_correlations( loan_scaled , umap_results) %>% 
  arrange(desc(abs_correlation)) %>% 
  head(10)

```

En el caso del modelo UMAP en tres dimensiones, no se identificó correlación significativa entre los componentes, lo que permite concluir que cada uno de ellos captura distintos aspectos de la estructura global de los datos.

```{r echo=FALSE}
umap_results %>% 
  cor(., method="spearman") %>% 
ggcorrplot::ggcorrplot(corr = . ,
                       type = "lower", 
                       show.diag = TRUE,
                       lab = TRUE, 
                       lab_size = 3)
```



# Conclusiones

### Modelo UMAP en 3 dimensiones

En conclusión, la implementación de UMAP permitió explorar la estructura latente de los datos y visualizar la variable respuesta en un espacio de menor dimensión. El uso de tres dimensiones resultó más adecuado, ya que mejoró la separación de la aprobación del crédito, especialmente en las proyecciones de los componentes 1 vs. 3 y 2 vs. 3. Además, se identificaron features que únicamente se correlacionan con el tercer componente, aportando nueva información al análisis. Finalmente, la matriz de covarianza entre las tres dimensiones se mantuvo cercana a cero, lo que sugiere que los componentes extraídos son prácticamente ortogonales y capturan información complementaria.


